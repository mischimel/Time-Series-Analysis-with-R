---
title: "R for Data Analytics Part 1, Lecture 4"
author: "Michèle Fille"
format: docx
prefer-html: true
editor: visual
toc: true
toc-depth: 4
error: false
warning: false
---

# Lecture 4 – Packages for Data Wrangling: dplyr and tidyr

## 4.1 Manipulating data with dplyr

### Exercise 4.1. dyplyr

#### Exercise 4.1: Practicing with dplyr Verbs and Pipes

Install the nycflights13 package and load it. Also load dplyr.

```{r}
#install.packages("nycflights13")

library(nycflights13)
library(dplyr)
```

a\) The data frame flights is now accessible to you. Use appropriate functions to inspect it:

-   How many rows and columns does it have?

-   What are the names of the columns?

-   Use ?flights to search for documentation on the data set (for what the columns represent).

```{r}
nrow(flights)
ncol(flights)
colnames(flights)
?flights
```

b)  Use dplyr to give the data frame a new column that is the amount of time gained or lost while flying (that is: how much of the delay arriving occurred during flight, as opposed to before departing).

-   Hint: If your new column doesn't show up with print(), look at the bottom of the output written in grey: Maybe there was not enough space to print it in your console window! In this case you use print(flights, width = Inf) to show all columns.

```{r}
flights <- mutate(flights, gain_in_air = arr_delay - dep_delay)
print(flights, width = Inf)
```

c\) Use dplyr to sort your data frame in descending order by the column you just created. Save it as a variable (or in the same one!)

```{r}
flights1 <- arrange(flights, desc(gain_in_air))
View(head(flights1))
```

d\) For practice, repeat the last 2 steps in a single statement using the pipe operator. You can clear your environmental variables to "reset" the data frame.

```{r}
flights2 <- flights %>% 
  mutate(gain_in_air = arr_delay - dep_delay) %>% # if atribute not already created
  arrange(desc(gain_in_air))
```

e\) Make a histogram of the amount of time gained using the hist() function from base R. Alternatively, you can use ggplot2 to create a histogram.

-   Hint: Use geom_histogram() to make a histogram with ggplot.

    ```{r}
    library(ggplot2)

    # histogram with base R:
    hist(flights$gain_in_air) 

    # histogram with ggplot2:
    ggplot(flights) +
      geom_histogram(mapping = aes(x = gain_in_air))
    ```

-   Bonus: Compare the two visualizations: what is different and why are they different?

    *In the first plot, the mode (the most frequent gain) has a count of over 150'000. In contrast, in the second plot, it has a count of over a bit over 100'000. The difference results from different binning: The bins ("intervals") used for counting the frequencies have different widths. The larger the intervals, the more occurances per interval!*

f\) On average, did flights gain or lose time?

-   Note: Use the na.rm = TRUE argument to remove NA values from your aggregation. Otherwise the result will be NA.

```{r}
mean(flights$gain_in_air, na.rm = TRUE) 
```

g\) Create a data.frame of flights headed to SeaTac ('SEA'), only including the origin, destination, and the gain_in_air column you created.

```{r}
to_sea <- flights %>%
  select(origin, dest, gain_in_air) %>%
  filter(dest == "SEA")
```

h\) On average, did flights to SeaTac gain or lose time?

```{r}
mean(to_sea$gain_in_air, na.rm = TRUE) 
```

i\) Consider flights from JFK to SEA. What was the average, min, and max air time of those flights?

-   Hint: Don’t forget to use the argument na.rm = TRUE in your aggregations.

-   Bonus: Try to use pipes so that you can answer the last question in one single statement!

```{r}
flights %>% 
  filter(origin == "JFK",
         dest == "SEA") %>% 
  summarize(avg_air_time = mean(air_time, na.rm = TRUE),
            min_air_time = min(air_time, na.rm = TRUE),
            max_air_time = max(air_time, na.rm = TRUE))
```

### Self-Study 4.1. dyplyr

#### Self-Study 4.1 - Task 1: Using dplyr for Grouping

Install the nycflights13 package (if needed) and load it. Also load dplyr. View the data set flights .

a\) What was the average departure delay in each month? Save this as a data frame dep_delay_by_month.

-   Hint: you'll have to perform a grouping operation then summarizing your data.

```{r}
dep_delay_by_month <- flights %>%
  group_by(month) %>% # creates a tibble that groups by month
  summarize(delay_avg = mean(dep_delay, na.rm = TRUE)) # calculates the mean departure delay per month

print(dep_delay_by_month)
```

b\) Which month had the greatest average departure delay?

```{r}
filter(dep_delay_by_month, delay_avg == max(delay_avg)) %>% 
  select(month)
```

c\) If your data frame dep_delay_by_month contains only two columns (e.g., "month", and "delay” in that order), you can create a scatterplot by passing that data frame directly to the base R function plot(). It is a generic function, that automatically makes a scatterplot when passed a data frame with 2 columns.

-   Alternatively, you can of course also use ggplot2 to create the scatterplot.

```{r}
# With base R:
plot(dep_delay_by_month) # notice that we only need to pass the data frame as is!

# With ggplot2:
# In this case, ggplot is more effort!! (BUT it's easier to pimp your plot so that it looks nicer :-D )
library(ggplot2)
ggplot(dep_delay_by_month) + 
  geom_point(mapping = aes(x = month, y = delay_avg))
```

d\) To which destinations were the average arrival delays the highest?

-   Hint: you'll have to perform a grouping operation then summarize your data. You can use the head() function to view just the first few rows for checking.

```{r}
arr_delay_by_month <- flights %>%
  group_by(dest) %>%
  summarise(delay_avg = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(-delay_avg)  # = arrange(desc(delay_avg))

head(arr_delay_by_month)
```

e\) The package nycflights13 also includes a data frame called airports. You can look up the above destinations in the airports data frame!

```{r}
head(airports)
filter(airports, faa == arr_delay_by_month$dest[1]) # for example we can look up teh first destination, which is CAE.

# see all destinations from above (would blow up the file size)
# airports %>%
#   filter(faa %in% arr_delay_by_month$dest)
```

f\) Which city was flown to with the highest average speed?

```{r}
city_fasted_speed <- flights %>%
  mutate(speed = distance / air_time * 60) %>%
  group_by(dest) %>%
  summarise(avg_speed = mean(speed, na.rm = TRUE)) %>%
  filter(avg_speed == max(avg_speed, na.rm = TRUE))

city_fasted_speed
```

#### Self-Study 4.1 - Task 2: Using the dplyr Join Operations

Install the nycflights13 package (if needed) and load it. Also load dplyr. View the data set flights .

a\) Create a dataframe of the average arrival delays for each destination from the flights data frame. Then use left_join() to join on the airports dataframe.

-   Remark: The airports dataframe is also part of the nycflights13 package and holds information about the airports.

```{r}
avg_delay <- flights %>%
  group_by(dest) %>%    # creates it as tibble that groups rows by destination
  summarise(avg_delay = mean(arr_delay, na.rm = TRUE))  # calculates the mean arrival delay per group

avg_delay_dest <- avg_delay %>%
  mutate(faa = dest) %>% # create a new column faa, so we can use it as join condition
  left_join(airports, by = "faa")

head(avg_delay)
head(avg_delay_dest)
```

b\) Which airport had the largest average arrival delay?

```{r}
largest_arrival_delay <- avg_delay_dest %>%
  filter(avg_delay == max(avg_delay, na.rm = TRUE))

print(largest_arrival_delay)
```

```{r}
# Notice that we could have done all the above in one single statement using pipes!
largest_arrival_delay <- flights %>%
  group_by(dest) %>%
  summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
  mutate(faa = dest) %>%
  left_join(airports, by = "faa") %>%
  filter(avg_delay == max(avg_delay, na.rm = TRUE))

print(largest_arrival_delay)
```

c\) Create a dataframe of the average arrival delay for each airline, then use left_join() to join on the airlines dataframe (which is also part of the nycflights13 package).

```{r}
head(airlines)

avg_delay_airline <- flights %>%
  group_by(carrier) %>%
  summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
  left_join(airlines, by = "carrier")

avg_delay_airline
```

d\) Which airline had the smallest average arrival delay?

```{r}
smallest_airline_delay <- avg_delay_airline %>%
  filter(avg_delay == max(avg_delay, na.rm = TRUE))

smallest_airline_delay
```

OR all in one

```{r}
smallest_airline_delay <- flights %>%
  group_by(carrier) %>%
  summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
  left_join(airlines, by = "carrier") %>%
  filter(avg_delay == max(avg_delay, na.rm = TRUE))

smallest_airline_delay
```

#### Self-Study 4.1 – Task 3: Comparing base R and dplyr

a\) Install and load dplyr if needed.

*Already done above*

b\) Install and load the fueleconomy package from GitHub as follows:

-   Install the devtools package (as usual).

-   The devtool package allows us to make installations from GitHub. Use the following command to install the fueleconomy package from GitHub: devtools::install_github("hadley/fueleconomy")

-   Load the fueleconomy package as usual.

```{r}
# install.packages("devtools")
# devtools::install_github("hadley/fueleconomy")
library(fueleconomy)
```

c\) Now you have access to the vehicles data frame. Use View() to get a first impression. Select from this data frame the column makes, which holds the different car manufacturers. Save it in the variable makes.

-   Hint: Since you made a selection on a data frame, the result is a vector.

```{r}
View(vehicles)

makes <- vehicles$make
```

d\) Use the function unique() to list and count the different car manufacturers. Alternatively, use the dplyr function distinct()to do the same. What is the difference?

```{r}
unique(makes) # returns a vector
length(unique(makes))
```

```{r}
distinct(vehicles, make) # returns a tibble
nrow(distinct(vehicles, make))
```

e\) Filter the data set for vehicles manufactured in 1997. Do it first with base R, then with dplyr alone, then with dplyr and piping.

```{r}
# With base R:
cars_1997 <- vehicles[vehicles$year == 1997, ] 
```

```{r}
# With dplyr:
cars_1997 <- filter(vehicles, year == 1997) 
```

```{r}
# With dplyr and piping:
cars_1997 <- vehicles %>%  
  filter(year == 1997) 
```

f\) Arrange (sort, order) the 1997 cars by highway (hwy) gas milage (in increasing order). Do it first with base R, then with dplyr alone, then with dplyr and piping.

-   Hint: In base R, use the order() function to get a vector of indices in order by value.

```{r}
# With base R:
cars_1997_byhwy <- cars_1997[order(cars_1997$hwy), ]  
```

```{r}
# With dplyr:
cars_1997_byhwy <- arrange(cars_1997, hwy)  
```

```{r}
# With dplyr and piping:
cars_1997_byhwy <- cars_1997 %>%  
  arrange(hwy)
```

g\) Mutate the ordered 1997 cars data frame to add a column average that holds the average gas milage (between city and highway mpg) for each car. Do it first with base R, then with dplyr alone, then with dplyr and piping.

```{r}
# With base R:
cars_1997_byhwy_av <- cars_1997_byhwy 
cars_1997_byhwy_av$average <- (cars_1997_byhwy_av$hwy + cars_1997_byhwy_av$cty) / 2
```

```{r}
# With dplyr:
cars_1997_byhwy_av <- mutate(cars_1997_byhwy, average = (hwy + cty) / 2) 
```

```{r}
# With dplyr and piping:
cars_1997_byhwy_av <- cars_1997_byhwy %>% 
  mutate(average = (hwy + cty) / 2)
```

h\) Filter the whole vehicles data set for 2-Wheel Drive vehicles that get more than 20 miles/gallon in the city. Save this new data frame in a variable. Do it first with base R, then with dplyr alone, then with dplyr and piping.

```{r}
# With base R:
two_wheel_20_mpg <- vehicles[vehicles$drive == "2-Wheel Drive" & vehicles$cty > 20, ]
```

```{r}
# With dplyr:
two_wheel_20_mpg <- filter(vehicles,
                           drive == "2-Wheel Drive",
                           cty > 20
)
```

```{r}
# With dplyr and piping:
two_wheel_20_mpg <- vehicles %>% 
  filter(drive == "2-Wheel Drive") %>% 
  filter(cty > 20)
```

i ) Of the above vehicles, what is the vehicle ID of the vehicle with the worst (i.e., smallest) hwy mpg? Do it first with base R, then with dplyr alone, then with dplyr and piping.

-   Hint: filter for the worst vehicle, then select its ID.

```{r}
# With base R:
worst_hwy <- two_wheel_20_mpg$id[two_wheel_20_mpg$hwy == min(two_wheel_20_mpg$hwy)] # Notice that there are two cars with the min hwy mpg!
```

```{r}
# With dplyr:
filtered <- filter(two_wheel_20_mpg, hwy == min(hwy))
worst_hwy <- select(filtered, id)
```

```{r}
# With dplyr and piping:
worst_hwy <- two_wheel_20_mpg %>% 
  filter(hwy == min(hwy)) %>% 
  select(id)
```

j\) Write a function that takes a year_choice and a make_choice as parameters, and returns the vehicle model that has the best (i.e., highest) hwy miles/gallon of vehicles of that make in that year. You'll need to filter more (and do some selecting)! Do it first with base R, then with dplyr alone, then with dplyr and piping.

```{r}
# With base R:
make_year_filter <- function(make_choice, year_choice) {
  filtered <- vehicles[vehicles$make == make_choice & vehicles$year == year_choice, ]
  filtered[filtered$hwy == max(filtered$hwy), "model"]
}
```

```{r}
# With dplyr:
make_year_filter1 <- function(make_choice, year_choice) {
  filtered <- filter(vehicles, 
                     make == make_choice,
                     year == year_choice)
  filtered <- filter(filtered, hwy == max(hwy))
  select(filtered, model)
}
```

```{r}
# With dplyr and piping:
make_year_filter2 <- function(make_choice, year_choice) {
  vehicles %>% 
    filter(make == make_choice,
           year == year_choice) %>% 
    filter(hwy == max(hwy)) %>% 
    select(model)
}
```

k\) What was the most efficient Honda model of 1995 ? (Use your function!)

```{r}
make_year_filter("Honda", 1995)
make_year_filter1("Honda", 1995)
make_year_filter2("Honda", 1995)
```

## 4.2 Reshaping data with tidyr

### Exercise 4.2. tidyr

#### Exercise 4.2 – Task 1: Plotting Time Series of Weights

Consider the following toy data set of weight time series per person:

```{r}
#install.packages("tidyr")
library(tidyr)

name <- c('ann', 'bob', 'charlie') 
jan <- c(102, 155, 211) 
feb <- c(112, 150, 211) 
mar <- c(123, 147, 213) 
apr <- c(130, 140, 210) 
wts <- tibble(name=name, jan=jan, feb=feb, mar=mar, apr=apr)
```

a\) Copy / paste it in your R-script, view it and answer the following questions:

-   What is the observed event?

    *A person has a weight in a specific month. Example: Ann weighs 102 pounds in January. (Note: Probably it's always measured on the same day of each month!)*

-   What are the recorded aspects of the event?

    *(1) Name, (2) Month, (3) Weight*

-   Is this data set tidy or messy?

    *messy*

-   If messy, describe in words how a tidy version of the data would look.

    *(1) Keep name as a column*

    *(2) Create a column month. Its values are the current column names of columns 2-5.*

    *(3) Create a column weight. Its values are the current values of these current columns.*

b\) Tidy up the data set using pivot_longer(). Store the result in a new data frame called wts_tidy.

```{r}
wts_tidy <- wts %>% pivot_longer(cols = jan:apr,  # messy part
                                 names_to = "month", # headers as values for month
                                 values_to = "weight" # values as vales for weight
                                 )
```

c\) Use geom_line() to plot the time series of weights per person. Hints:

-   Map month to the x-axes.

-   Map weight to the y-axes.

-   Map name to the color scale.

-   Additionally, use the argument group = name within the aesthetic of geom_line() to group observations by person. Otherwise, geom_line() tries to connect all obersvations with a single line, which does not work.

```{r}
wts_tidy %>% 
  ggplot() +
  geom_line(mapping = aes(x = month, 
                          y = weight, 
                          col = name, 
                          group = name))
```

d\) Notice that the months in your x-axes are ordered alphabetically. That's not the order we want! To change that, use mutate() to change the column month from integer to "ordered factor". Hint:

-   An "ordered factor" is a normal factor, but with an order that we define manually.

-   do that, use the arguments ordered and level as follows: factor(month, ordered = TRUE, levels = c('jan', 'feb', 'mar', 'apr’))

```{r}
wts_tidy <- wts_tidy %>% 
  mutate(month = factor(month,
                        ordered = TRUE,
                        levels = c('jan', 'feb', 'mar', 'apr')))
```

e\) Now redo the plot. The months will now appear in the order you specified above.

```{r}
wts_tidy %>% 
  ggplot() +
  geom_line(mapping = aes(x = month, 
                          y = weight, 
                          col = name, 
                          group = name))
```

f\) Now calculate the minimal, maximal and average weight per person.

-   Hint: Use group_by() and summarize() from dplyr.

```{r}
wts_tidy_agg <- wts_tidy %>% 
  group_by(name) %>% 
  summarize(min = min(weight),
            max = max(weight),
            avg = mean(weight)
            )
```

#### Exercise 4.2 – Task 2: German Car Manufacturers

The following (made-up) data set lists different German car manufacturers. It reports how many models with a specified number of cylinders have been built per manufacturer.

```{r}
set.seed(3) 
cars <- tibble( manufacturer = c("Audi", "BMW", 
                  "Mercedes", "Opel", "VW"), 
                            `3 cyl` = sample(20, 5, replace = TRUE), 
                            `4 cyl` = sample(50:100, 5, replace = TRUE),
                            `5 cyl` = sample(10, 5, replace = TRUE),
                            `6 cyl` = sample(30:50, 5, replace = TRUE), 
                            `8 cyl` = sample(20:40, 5, replace = TRUE), 
                            `10 cyl` = sample(10, 5, replace = TRUE), 
                            `12 cyl` = sample(20, 5, replace = TRUE), 
                            `16 cyl` = rep(0, 5) 
) 
```

a\) Copy / paste the above code in your R-script, view the data set, and answer the following questions:

-   What is the observed event?

    *A manufacturer produces a certain number of cars with a certains number of cylinders. (Example: Audi builds 5 cars with 3 cylinders.)*

-   What are the recorded aspects of the event?

    *(1) manufacturer, (2) number of cylinders, (3) number of cars*

-   Is this data set tidy or messy?

    *messy*

-   If messy, describe in words how a tidy version of the data would look.

    *(1) Keep 'manufacturer' as a column.*

    *(2) Create a column 'cyl'. Its values are the current column names of columns 2-5.*

    *(3) Create a column 'freq'. Its values are the current values of columns 2-5.*

b\) Tidy up the data set using pivot_longer(). Store the result in a new data frame cars_tidy.

```{r}
cars_tidy <- cars %>% pivot_longer(cols = -manufacturer,
                                   names_to = "cyl",
                                   values_to = "freq")
```

c\) Use geom_col() to create a bar plot that shows the frequency per cylinder. Use facet_wrap() to create one such plot per manufacturer. Use ggplotly() to make it interactive.

-   Hint: Don’t forget to load the library plotly.

```{r}
library(plotly)

p_tidy_cars <- cars_tidy %>% ggplot() +
  geom_col(mapping = aes(x = cyl,
                         y = freq)) +
  facet_wrap(~ manufacturer)

p_tidy_cars # not interactive

#ggplotly(p_tidy_cars) # does not work as pdf output
```

d\) Notice that the number of cylinders is not in a natural order. To change that, use mutate() to change the data type of the variable cyl. To do that, you have 2 options:

1.  You can either convert the variable cyl in an ordered factor,

2.  or you can use gsub("\\D", "", cyl) and as.numeric() to extract the numbers from the strings.

Try out both options!

```{r}
# Option 1: converting it 'cyl' in an ordered factor:
cars_tidy1 <- cars_tidy %>% 
  mutate(cyl = factor(cyl,
                      ordered = TRUE,
                      levels = c("3 cyl", "4 cyl", "5 cyl", "6 cyl", "8 cyl", "10 cyl", "12 cyl", "16 cyl")
                     )
         )
```

```{r}
# Option 2: using gsub() to extract the numbers from the strings
cars_tidy2 <- cars_tidy %>% 
  mutate(cyl = as.numeric(gsub("\\D", "", cyl))) # All non-numbers (\\D) are replaced by the empty string ("").

```

e\) Redo the plot for both options.

```{r}
p_tidy_cars1 <- cars_tidy1 %>% ggplot() +
  geom_col(mapping = aes(x = cyl,
                         y = freq)) +
  facet_wrap(~ manufacturer)

p_tidy_cars1  # not interactive

#ggplotly(p_tidy_cars1) # does not work as pdf output
```

```{r}
p_tidy_cars2 <- cars_tidy2 %>% ggplot() +
  geom_col(mapping = aes(x = cyl,
                         y = freq)) +
  facet_wrap(~ manufacturer)

p_tidy_cars2  # not interactive

#ggplotly(p_tidy_cars2) # does not work as pdf output
```

-   Do you notice a difference?

    *- When using gsub(), cyl is converted to numbers, and thus, ggplot puts a number scale on the x-axes.*

    *Thus, there is a slot reserved for, e.g., 7 cylinders, even though cars with 7 cylinders do not exist!*

    *On the other hand, cars with 16 cylinders exist, but zero are produced.*

    *When using this option we cannot distinguish between 'non-existing' and 'zero'!*

    *- This does not happen when we use ordered factors.*

-   Which option is better for visualization?

    *- Thus, ordered factors are the better option for visualization!*

### Self-Study 4.2. tidyr

#### Self-Study 4.2: Analyzing Avocado Sales with tidyr and dplyr

a\) Load the packages tidyr, dplyr, and ggplot2. Download the avocado.csv file from GitHub and load it into a variable avocados. Get a first impression of the data using View() and str().

```{r}
avocados <- read.csv("avocado.csv")

str(avocados)
View(avocados) 
```

b\) From str(), you can see that the Date column is of type char. To tell R to treat the Date column as a date and not as a string, transform that column using the as.Date() function.

-   Hint: You can use mutate().

```{r}
avocados <- avocados %>% 
  mutate(Date = as.Date(Date))

str(avocados)
```

c\) The file has some uninformative column names. Rename these columns:

-   X4046 to small_haas

-   X4225 to large_haas

-   X4770 to xlarge_haas

These are the sales volumes of haas avocados.

```{r}
avocados <- avocados %>% 
  rename(small_haas = X4046, 
         large_haas = X4225, 
         xlarge_haas = X4770)

str(avocados)
```

d\) The data only holds total sales volumes (Total.Volume) and the sales volumes for haas avocados (small_haas, large_haas, xlarge_haas), but there are also other avocados included in Total.Volume. Double-check this by summing up haas avocado sales and comparing the sum with the total sales value.

```{r}
sum(avocados$Total.Volume - (avocados$small_haas + avocados$large_haas + avocados$xlarge_haas) > 0) # 18237 out of 18249 (This is the number of records in  of the data set.) It means that 18237 out of 18249 days the Total Sales Volume is bigger than the Sales Volume of haas avocados.
```

e\) Create a new column other_avos that is the Total.Volume minus all haas avocados (small, large, xlarge).

```{r}
avocados <- avocados %>% 
  mutate(other_avos = Total.Volume - small_haas - large_haas - xlarge_haas)
```

f\) To perform analysis by avocado size, create a dataframe by_size that has only Date, other_avos, small_haas, large_haas, xlarge_haas.

-   Note: other_avos is not strictly a size, but we ignore this. We may view it as the bin that holds the sales volumes of avocados of size “unknown”.

```{r}
by_size <- avocados %>% 
  select(Date, 
         other_avos, 
         small_haas, 
         large_haas, 
         xlarge_haas)
```

g\) Use head() to view the first few lines of your dataframe by_size.

-   Is it tidy or messy?

    *messy*

-   What is the observed event?

    *At a certain date, a number of avocados of a certain size are sold.*

-   What are the recorded aspects?

    *(1) date, (2) size, (3) number sold.*

-   How would a tidy version of the data look?

    *(1) keep 'date' column.*

    *(2) create a 'size' column that holds the column names `other_avos`, `small_haas`, `large_haas`, `xlarge_haas` as values.*

    *(3) create a 'volume' column that holds the sales volumes.*

```{r}
head(by_size) 
```

h\) Tidy it up using pivot_longer(). Store the result in a new data frame by_size_tidy. Hints:

-   The four column names other_avos, small_haas, large_haas, xlarge_haas go into a new column called size.

-   The volumes of sales (currently stored in each of the above columns) go to a new column called volume.

```{r}
by_size_tidy <- by_size %>% 
  pivot_longer(cols = -Date,
               names_to = "size",
               values_to = "volume"
               )

head(by_size_tidy) 
```

i\) The shape of by_size_tidy is not only tidier, but it also facilitates the visualization of sales over time by size: Use ggplot2 with geom_smooth() to plot a smoothed trendline of sales volumes over time – make one trendline for each size. Hints:

-   Map the Date to the x-axes, map the volume to the y-axes, map the size to the colour scale.

-   Inside of geom_smooth(), you can set the argument se = F to hide the confidence bands around the trendlines.)

Bonus:

-   To see the advantage of this shape for plotting sales over time by size, try to produce the same plot using the data frame by_size instead of the data frame by_size_tidy.

```{r}
ggplot(by_size_tidy) +
  geom_smooth(mapping = aes(x = Date,
                           y = volume,
                           col = size),
              se = F) # Don't display the confidence intervals around the smoothed conditional means
```

```{r}
by_size %>% ggplot() +
  geom_smooth(mapping = aes(x = Date,
                            y = small_haas, color = "Small Haas"), se = F) +    # specify you own label for 'color' inside aes(), e.g., color = "Small Haas". You can use whatever label you wish to appear in the legend (see below)
  geom_smooth(mapping = aes(x = Date,
                            y = large_haas, color = "Large Haas"), se = F) +
  geom_smooth(mapping = aes(x = Date,
                            y = xlarge_haas, color = "Xlarge Haas"), se = F) +
  geom_smooth(mapping = aes(x = Date,
                            y = other_avos, color = "Other"), se = F) +
  labs(x = "Date", y = "volume") + # Specify the title for the axes
  scale_color_manual(name = "", values = c("Small Haas" = "red", "Large Haas" = "blue", "Xlarge Haas" = "green", "Other" = "yellow")) # the labels must match what you specified above
```

j\) Now use by_size_tidy to compute the average sales volume per size.

-   Hint: First group by size using group_by(), then compute the average using summarize().

```{r}
average_sales <- by_size_tidy %>% 
  group_by(size) %>% 
  summarize(avg_volume = mean(volume))

print(average_sales)
```

k\) We can also investigate sales by avocado type (conventional, organic).

-   To do this, consider again the original avocados data frame.

-   Group it by Date and type, and

-   calculate the sum of the column Total.Volume for each group.

-   Store the result in a new data frame called by_type.

```{r}
by_type <- avocados %>% 
  group_by(Date, type) %>% 
  summarise(volume = sum(Total.Volume), .groups = 'drop') # .groups = 'drops' needed, without I get an error
```

l\) This data set is already tidy. Visualize the avocado sales over time by type using geom_smooth().

-   Note: This is completely analogous to the plot you did before!

```{r}
ggplot(by_type) +
  geom_smooth(mapping = aes(x = Date,
                            y = volume,
                            col = type),
              se = F)
```

m\) From the above plot we see that the sales volumes of both avocado types seem to increase over the years. Now let’s see if we can (visually) confirm this correlation in a scatterplot: if our assumption is correct, we should see a linear correlation between conventional and organic sales. Create this scatterplot using ggplot2. Hints:

-   In order to check for a linear correlation between the types, we must map conventional sales to the x-axes and organic sales to the y-axes.

-   Yet, in the data frame by_type the sales numbers for both avocado types are mingled in one column, namely volume.

-   To facilitate the plotting, it would be good to have one column per type, each holding the respective sales numbers. Then we could simply map each column to an axes.

-   To achieve this, reformat the data frame by_type using pivot_wider(). Store the result in a new data frame called by_type_wide.

-   Now use ggplot2 with geom_point() to generate the scatterplot. Does it confirm our assumption?

```{r}
by_type_wide <- by_type %>% 
  pivot_wider(names_from = type, 
              values_from = volume)

ggplot(by_type_wide) +
  geom_point(mapping = aes(x = conventional, 
                           y = organic)) 
```

*As expected, the scatter plot shows some linear correlation between the sales numbers, but it is not too strong. This was expected as well: We could already see in the temporal plot that conventional sales vary much stronger than organic sales, which is reflected in the relatively wide spread of points.*
